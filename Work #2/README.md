
# Первая программа на CUDA

CUDA (Compute Unified Device Architecture) — это параллельная вычислительная платформа и API от NVIDIA, которая позволяет использовать графические процессоры (GPU) общего назначения, в том числе для вычислений, требующих больших объемов параллельной обработки. В CUDA ключевыми концепциями являются "блоки" (blocks) и "потоки" (threads), которые используются для организации выполнения параллельных операций.

**Поток** — это основная единица выполнения в CUDA. Поток содержит фрагмент кода, который требуется многократно повторить.  Каждый поток в CUDA имеет уникальный идентификатор, который используется для различения потоков и управления их поведением. Идентификаторы потоков обычно представляют собой одномерные или многомерные индексы (например, 1D, 2D, 3D). Каждый поток имеет доступ к собственному регистру и локальной памяти, а также может использовать общий доступ к глобальной памяти, которая доступна всем потокам на GPU.

Количество параллельных потоков ограничено количеством CUDA-ядер GPU. Для современных моделей это 1024 и больше. Если требуется выполнение большего количества одновременных вычислений, то такие вычисления группируются на блоки. Так, например, 1025-е вычисление начнется после того, как освободится хотя бы одно из 1024 ядер. Чтобы такую работу можно было удобнее организовать, применяется разделение на блоки.

**Блок** — это группа потоков, которые могут работать совместно и обмениваться данными через общую память. Блоки могут иметь одномерную, двумерную или трехмерную структуру, что позволяет эффективно организовывать вычисления для различных типов задач. Например, обработка изображений может быть удобно выполнена с использованием двумерных блоков.

Количество блоков и потоков в каждом из них указывается в момент запуска ядра. Ниже шаблон вызова и пример:

ИмяФункции<<<количБлоков, количПотоковВБлоке>>>(аргументы);

``` cuda
#include <cstdio>

__global__
void first_kernel()
{
   printf("I'm %i thread in %i block. BlockSize is %i \n", threadIdx.x,  blockIdx.x, blockDim.x);
}

int main(){
   first_kernel<<<3, 5>>>();
   system("pause");
}
```

Внутри потока мы можем создавать локальные переменные, массивы. Мы можем свободно обращаться к аргументам функции, а также в глобальную память. Однако взаимодействие между потоками запрещено. 

Обратите внимание на переменные threadIdx, blockIdx и blockDim. Они будут верными помощниками в определении идентификатора потока. 

Задание: попробуйте модифицировать программу таким образом, чтобы выводился также уникальный номер потока от 0 до 15. 

При необходимости мы можем использовать `__syncthreads()` для ожидания завершения всех потоков. 
Дополните first_kernel следующим кодом:

``` cuda
__global__
void first_kernel()
{
   printf("I'm %i thread in %i block. BlockSize is %i \n", threadIdx.x,  blockIdx.x, blockDim.x);
   __syncthreads();
   printf("Second part \n");
}
```

При работе с CUDA важно помнить о том, что:
1. Не на всех компьютерах есть видеокарты с поддержкой CUDA
2. Не все программы возможно распараллелить
3. CUDA-ядра значительно уступают в производительности CPU-ядрам
4. Обмен CPU-RAM и GPU-RAM может отнимать много времени
5. Неумелое использование памяти может приводить к снижению быстродействия программы

# Профилировка программы CUDA
Прежде, чем продолжить, мне бы хотелось рассказать про 2 средства для оценки скорости работы программы.  

## 1. Утилита nvprof
Вызывается она через командную строку, где в качестве аргумента указывается исполняемый файл с CUDA-кодом. Выводом её работы является таблица, аналогичная представленной ниже:

```
==49352== NVPROF is profiling process 49352, command: C:\temp\1.exe
==49352== Profiling application: C:\temp\1.exe
==49352== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:  100.00%  2.7840us         1  2.7840us  2.7840us  2.7840us  first_kernel(void)
      API calls:   82.86%  249.32ms         1  249.32ms  249.32ms  249.32ms  cudaLaunchKernel
                   17.11%  51.475ms         1  51.475ms  51.475ms  51.475ms  cuDevicePrimaryCtxRelease
                    0.01%  43.400us         1  43.400us  43.400us  43.400us  cuModuleUnload
                    0.01%  35.700us         1  35.700us  35.700us  35.700us  cuDeviceTotalMem
                    0.01%  20.100us       101     199ns     100ns  1.1000us  cuDeviceGetAttribute
                    0.00%  4.9000us         3  1.6330us     400ns  3.8000us  cuDeviceGetCount
                    0.00%  1.9000us         2     950ns     200ns  1.7000us  cuDeviceGet
                    0.00%  1.0000us         1  1.0000us  1.0000us  1.0000us  cuDeviceGetName
                    0.00%     500ns         1     500ns     500ns     500ns  cuDeviceGetLuid
                    0.00%     200ns         1     200ns     200ns     200ns  cuDeviceGetUuid
```

Из этой таблицы можно понять, сколько времени выполнялся код на видеокарте (GPU activities), сколько времени заняли операции пересылки памяти (cuDeviceTotalMem), а сколько инициализация и запуск ядра (cudaLaunchKernel). 

# Функции cudaEvent
Вторым помощником в отладке программ являются Cuda_Event. События позволяют создавать временные метки, и вычислять время, прошедшее между ними. 

Если у Вас свежая версия компилятора C++, то я предлагаю использовать следующий код:

``` cuda
void profiler(void(*op)(), int count){
   for (int i = 0; i < count; i++){
	
      // Получение времени запуска функции op
      cudaEvent_t start, stop;
      cudaEventCreate(&start);
      cudaEventCreate(&stop);
      cudaEventRecord(start, 0);

      // Запуск функции
      op();
      
      // Остановка таймера и вычисление времени выполнения
      cudaEventRecord(stop, 0);
      cudaEventSynchronize(stop);
      float elapsedTime;
      cudaEventElapsedTime(&elapsedTime, start, stop); // that's our time!
      cudaEventDestroy(start);
      cudaEventDestroy(stop);
	  
      std::cout << "Elapsed Time (in ms): " << elapsedTime << std::endl;	
   }
}
```

В функцию profiler передается функция (op), которую необходимо протестировать. Данный фрагмент кода прогонит её count раз и выведет время, затраченное на её выполнение. 

Задание на самостоятельную работу:

Для чисел от 2 до 10000000 напишите программу на C++ и на CUDA, которая определяет, является ли число простым. Для определения, является ли число простое требуется использовать метод полного всех возможных множителей от 2 до N.
Сравните, кто быстрее решает данную задачу: CPU или GPU. Сделайте выводы.

## Вопросы на защиту:
1. Назовите основные отличия CPU от GPU
2. Дайте определение технологии NVidia CUDA. 
3. Для каких задач может применяться CUDA?
4. Что такое CUDA-ядро. Определите их количество для Вашей видеокарты.
5. Что такое thread?
6. Что такое block?
7. В каких случаях применение CUDA нецелесообразно?
8. Что такое профилировка? Когда она может быть полезна?

